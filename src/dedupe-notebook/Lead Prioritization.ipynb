{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fe95640e-3a7c-47ff-b62c-90c6607eaadb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM `hive_metastore`.`default`.`ice_data_2025_02_28_135500_2_csv` where is_dupe = \"False\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d2ffc82-267f-437e-abf4-9dcbfb8afa9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = spark.table(\"hive_metastore.default.ice_data_2025_02_28_135500_2_csv\").toPandas()\n",
    "df.head()\n",
    "\n",
    "# filter to just is_dupe = False\n",
    "df = df[df['is_dupe'] == 'False']\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c72fa2fb-8004-4e88-a2fd-74b4fcffd04d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "654bb7e6-c357-4b91-b2ff-d89e02a821ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "024f5ecb-21c2-4449-bb4c-3b43e9a129a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load the airports GIS data\n",
    "df_airports = spark.table(\"default.international_airports_lower_48\").toPandas()\n",
    "df_airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84c4e7f7-2b9f-4d25-a62a-cb84a68adaff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# add a haversine distance formula\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371\n",
    "    # return distance in miles\n",
    "    miles = c * r * 0.621371\n",
    "    return miles\n",
    "\n",
    "# find the closest airport for each ice lead\n",
    "def find_closest_airport(row):\n",
    "    min_distance = float('inf')\n",
    "    closest_airport = None\n",
    "    for _, airport in df_airports.iterrows():\n",
    "        distance = haversine(float(row['longitude']), float(row['latitude']), float(airport['Longitude']), float(airport['Latitude']))\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_airport = airport['Airport Name']\n",
    "    return pd.Series([closest_airport, min_distance], index=['closest_airport', 'distance_to_airport'])\n",
    "\n",
    "df[['closest_airport', 'distance_to_airport']] = df.apply(find_closest_airport, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f6b01cc-19bb-4c08-bc0f-e14a4c318b22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df.head()\n",
    "\n",
    "# For verfication, select just the lead_id, address, closest airport, and distance for rows with an address\n",
    "verification_df = df[['lead_id', 'last_known_address', 'closest_airport', 'distance_to_airport']][df['last_known_address'].notnull()]\n",
    "\n",
    "# show the top 10 leads closest to an airport\n",
    "closest_df = verification_df.sort_values(by='distance_to_airport')\n",
    "display(closest_df.head(10))\n",
    "\n",
    "# show the top 10 furthest leads from an airport\n",
    "furthest_df = verification_df.sort_values(by='distance_to_airport', ascending=False)\n",
    "display(furthest_df.head(10))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7efe543a-7556-45f0-a568-df906bc26323",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create some weighted prioritization functions\n",
    "\n",
    "# lead needs to have an address\n",
    "def address_weight(row):\n",
    "    return 5 if pd.notnull(row['last_known_address']) else 0\n",
    "\n",
    "def risk_weight(row):\n",
    "    if row['risk_level'] == 'High':\n",
    "        return 5\n",
    "    if row['risk_level'] == 'Medium':\n",
    "        return 3\n",
    "    return 1\n",
    "\n",
    "def airport_weight(row):\n",
    "    if row['distance_to_airport'] < 100:\n",
    "        return 5\n",
    "    if row['distance_to_airport'] < 250:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "def organized_crime_weight(row):\n",
    "    # if pd null return 0, otherwise 5\n",
    "    if pd.notnull(row['organized_crime_links']):\n",
    "        return 5\n",
    "    return 0\n",
    "\n",
    "def country_of_origin_is_central_america(row): \n",
    "    # Mexico, Guatemela, Hondurus \n",
    "    if row['country_of_origin'] in ['Mexico', 'Guatemala', 'Honduras']:\n",
    "        return 5\n",
    "    if row['country_of_origin'] == 'India':\n",
    "        return 1\n",
    "    return 0\n",
    "    \n",
    "\n",
    "def prioritize(row):\n",
    "    return (address_weight(row) + risk_weight(row) + airport_weight(row) + organized_crime_weight(row) + country_of_origin_is_central_america(row))\n",
    "\n",
    "# add a \"lead_prioritization number\" column with the weighted score separate from the lead prioritization field\n",
    "df['lead_prioritization_number'] = df.apply(prioritize, axis=1)\n",
    "\n",
    "# create a validation df with the columns used for weighting, the lead id, and the weighted score\n",
    "verification_df = df[['lead_prioritization_number', 'lead_id', 'last_known_address', 'risk_level', 'distance_to_airport', 'organized_crime_links', 'country_of_origin' ]]\n",
    "\n",
    "# filter to the top 5 scores and diplay\n",
    "display(verification_df.sort_values(by='lead_prioritization_number', ascending=False).head(5))\n",
    "\n",
    "# filter to the bottom 5 scores and diplay\n",
    "display(verification_df.sort_values(by='lead_prioritization_number').head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c97d9b6b-7261-417c-b3b9-81fa01147bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# show a distribution of the scores\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['lead_prioritization_number'], bins=20, edgecolor='k', alpha=0.7)\n",
    "plt.title('Distribution of Lead Prioritization Scores')\n",
    "plt.xlabel('Lead Prioritization Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dcddc02-5942-4e42-a966-4c3be50591c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate quartiles\n",
    "quartiles = np.percentile(df['lead_prioritization_number'], [25, 50, 75])\n",
    "\n",
    "# Create a figure and axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(df['lead_prioritization_number'], bins=20, edgecolor='k', alpha=0.7)\n",
    "\n",
    "# Add vertical lines for quartiles\n",
    "for quartile in quartiles:\n",
    "    plt.axvline(quartile, color='r', linestyle='dashed', linewidth=1)\n",
    "\n",
    "# Add text for quartiles\n",
    "for i, quartile in enumerate(quartiles):\n",
    "    plt.text(quartile, plt.ylim()[1] * 0.9, f'Q{i+1}', color='r', ha='center')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution of Lead Prioritization Scores with Quartiles')\n",
    "plt.xlabel('Lead Prioritization Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98c5671a-f182-4dbd-89e4-fdddfdbbfc87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# update the lead_prioritization field to be High is score > 18, Medium if 18 >= score > 15, and Low if score <= 15\n",
    "df['lead_prioritization'] = df['lead_prioritization_number'].apply(lambda x: 'High' if x > 18 else ('Medium' if x > 15 else 'Low'))\n",
    "\n",
    "display(df[['lead_id', 'lead_prioritization', 'lead_prioritization_number']].head(10))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 140516381327372,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Lead Prioritization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
